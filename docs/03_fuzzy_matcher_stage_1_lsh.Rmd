---
title: "03 Fuzzy Matcher Stage 1 (Locality Sensitive Hashing) "
author: "Rex W. Douglass and Kristen Harkness"
date: "March 9, 2018"
output: 
  html_notebook:
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: inline
---
<style>
    body .main-container {
        max-width: 100%;
    }
</style>

# Fuzzy Matcher Stage 1

The fuzzy matcher predicts the likelihood that two toponyms are the same place even though their spellings might be different. It has two stages.

This file develops Stage 1 of the fuzzy toponym matcher. Its job is to screen out the vast majority of suggestions that are too dissimilar to ever be a plausible match. It will have a high false positive rate, which can then be further refined in stage 2.


```{r , results='hide', message=FALSE, warning=FALSE}
rm(list=ls()); gc()
library(MeasuringLandscape)
library(partykit) 

devtools::load_all()

dir_figures <- glue::glue(here::here(), "/paper/figures/")

knitr::opts_knit$set(progress = TRUE, verbose = TRUE)
knitr::opts_chunk$set(fig.width='100%',  warning=FALSE, message=FALSE, cache=TRUE)
options(width = 160)

```

# Load Hand Labeled Place Matches


```{r}

#Load Hand Labeled Examples
handlabeled <- fread(system.file("extdata",
                                 "event_flatfile_matches_for_hand_labeling - event_flatfile_matches_for_hand_labeling.csv",
                                 package = "MeasuringLandscape"), data.table=T) %>% distinct() 
dim(handlabeled)

# Remove exact matches 
# Rewrote  with foreach to run in parallel on windows, but it's still relatively slow code with 8 cores.
handlabeled$stemmed_a <- strip_postfixes(to_be_striped=handlabeled$name_cleaner_a)[[1]]
handlabeled$stemmed_b <- strip_postfixes(to_be_striped=handlabeled$name_cleaner_b)[[1]]

handlabeled_unique <- subset(handlabeled, stemmed_a!=stemmed_b) # very important we're dropping any with identical stems for evaluation
table(handlabeled_unique$rex_match) #1090 matches, 16978 nonmatches

#Stem them
handlabeled_unique$stemmed_a <- strip_postfixes(handlabeled_unique$name_cleaner_a)[[1]]
handlabeled_unique$stemmed_b <- strip_postfixes(handlabeled_unique$name_cleaner_b)[[1]]
handlabeled_unique$stemmed_ab <- sapply(lapply(strsplit(paste(handlabeled_unique$stemmed_a,
                                                              handlabeled_unique$stemmed_b, sep="_"),
                                                        "_"),
                                               sort),
                                        paste,
                                        collapse="_")


dim(handlabeled)
handlabeled$a <- handlabeled$name_cleaner_a
handlabeled$b <- handlabeled$name_cleaner_b
handlabeled[,ab:=paste(a,b,sep="_")]
handlabeled[,ba:=paste(b,a,sep="_")]

stemmed_ab <- unique(c(handlabeled$stemmed_a, handlabeled$stemmed_b)) ; length(stemmed_ab) #where ab is the unique toponym strings found in the data

```

Grid search optimal parameters for locality sensitive hashing.

Settling on 20 bands, 5 rows, and qgram of 1 letter

```{r}

fromsrcatch=F
if(fromsrcatch){
  grid_search_lhs <- list()
  for(q in c(2,5,10,20,25,50)){
    print(q)
    grid_search_lhs[[as.character(q)]] <- lhs_textreuse(minhash_count=100,  bands=q) #good trade off
    print(grid_search_lhs[[as.character(q)]])
  }
  grid_search_lhs_dt <- rbindlist(grid_search_lhs)
  
  saveRDS(grid_search_lhs_dt,
          glue::glue(getwd(), "/../inst/extdata/grid_search_lhs_dt.Rds"))
}

grid_search_lhs_dt <- readRDS(system.file("extdata", "grid_search_lhs_dt.Rds", package = "MeasuringLandscape"))

```

There's a big discontinuity between 50 bands and 25, and then diminishing returns with increasingly higher false negative rates thereafter. Choosing 25 as a compromise between low false negative rate and fewer suggestions per case. (Appendix Figure 4)

```{r}

p_lhs_gridsearch <- ggplot(grid_search_lhs_dt, aes(x=false_negative,y=suggestions_per, label=bands)) + geom_label() + ggtitle("")
p_lhs_gridsearch

ggsave(
  filename = glue::glue(dir_figures, "p_lhs_gridsearch.pdf"),
  plot = p_lhs_gridsearch,
  width = 5.5,
  #height = 8,
  device = cairo_pdf #have to use cairo to correctly embed the fonts
)

```





```{r, eval=F, echo=F}

nthread=parallel::detectCores()
pairwise_cor <- list()

for(i in 1:3){
  print(i)
  #handlabeled[, q_gram := stringsim(a, b, "cosine", nthread = nthread, q = i), ]
  
  #pairwise_cor[[i]] <- data.frame(q=i,
  #                                correlation= cor(handlabeled$q_gram , handlabeled$rex_match, use="pairwise.complete.obs", method="spearman")
  #                                )
  
  # First we hash each toponym, size 4, no skips
  # 3 grams is nearly as close but has a third of the columns
  ab_grams <- quanteda::dfm(
                  quanteda::tokens(
                                   stemmed_ab,
                                   what = "character",
                                   ngrams = 1:i,
                                   skip = 0:1, 
                                   concatenator = "_"
                                   # , hash=F
                                   )
                  )
  ab_grams <- as(ab_grams, "dgCMatrix")
  class(ab_grams)
  dim(ab_grams)
  rownames(ab_grams) <- stemmed_ab    

  #On how to scale the columns of a sparse matrix
  #https://stackoverflow.com/questions/39284774/column-rescaling-for-a-very-large-sparse-matrix-in-r
  #p_load('proxy') # Library of similarity/dissimilarity measures for 'dist()'
  ab_grams_scaled <- ab_grams
  ab_grams_scaled@x <- ab_grams_scaled@x / rep.int(colSums(as.matrix(ab_grams_scaled)), diff(ab_grams_scaled@p)) #added stuff here
  
  #ab_grams_scaled <- scale(ab_grams)
  x=as.matrix(ab_grams_scaled[handlabeled$stemmed_a,]) #Lookup by rownames. Not the safest.
  y=as.matrix(ab_grams_scaled[handlabeled$stemmed_b,]) #Lookup by rownames. Not the safest.
  handlabeled$q_gram_cosine_similarity <- 1 - 
                                          proxy::dist(x,y, method="cosine", pairwise=T, #
                                          by_rows=T #counter intuitive but right
                                          ) #Takes a short while but is pretty fast
  
  boxplot(q_gram_cosine_similarity ~rex_match , data=handlabeled)
  
  pairwise_cor[[as.character(i)]] <- data.frame(grams=i,
                                  correlation= cor(handlabeled$q_gram_cosine_similarity,
                                                   handlabeled$rex_match,
                                                   use="pairwise.complete.obs",
                                                   method="pearson")
                                  )
}
pairwise_cor_df  <- data.table::rbindlist(pairwise_cor)
pairwise_cor_df

ggplot(pairwise_cor_df, aes(x=grams,y=correlation)) + geom_point() + 
  ggtitle("Pairwise Correlation with Human Labeled Matches") + xlab("Qgram Size")


```


```{r, eval=F, echo=F}

ab_grams <- quanteda::dfm(
                quanteda::tokens(
                                 stemmed_ab,
                                 what = "character",
                                 ngrams = 1:2,
                                 skip = 0:1, 
                                 concatenator = "_" #,
                                 # hash = F
                                 )
                )
ab_grams <- as(ab_grams, "dgCMatrix")
class(ab_grams)
dim(ab_grams)
rownames(ab_grams) <- stemmed_ab    

#On how to scale the columns of a sparse matrix
#https://stackoverflow.com/questions/39284774/column-rescaling-for-a-very-large-sparse-matrix-in-r
#p_load('proxy') # Library of similarity/dissimilarity measures for 'dist()'
ab_grams_scaled <- ab_grams
ab_grams_scaled@x <- ab_grams_scaled@x / rep.int(colSums(as.matrix(ab_grams_scaled)), diff(ab_grams_scaled@p))

#ab_grams_scaled <- scale(ab_grams)
x=as.matrix(ab_grams_scaled[handlabeled$stemmed_a,]) #Lookup by rownames. Not the safest.
y=as.matrix(ab_grams_scaled[handlabeled$stemmed_b,]) #Lookup by rownames. Not the safest.
handlabeled$q_gram_cosine_similarity <- 1 - 
                                        proxy::dist(x,y, method="cosine", pairwise=T, #
                                        by_rows=T #counter intuitive but right
                                        ) #Takes a short while but is pretty fast

#p_load('proxy') # Library of similarity/dissimilarity measures for 'dist()'
handlabeled$q_gram_2_cosine_similarity <- 1 - proxy::dist(x,y, method="cosine", pairwise=T, 
           by_rows=T #counter intuitive but right
            ) #Takes a short while but is pretty fast

#Cosine distance on a qgram is a little different than normalized string distance
ggplot(handlabeled, aes(y=q_gram_2_cosine_similarity, x=as.factor(rex_match))) + geom_boxplot() + 
  ggtitle("Pairwise Correlation with Human Labeled Matches") + xlab("No Match/Match") + ylab("Cosine Similarity")



handlabeled$q_gram_cosine_similarity <- as.numeric(handlabeled$q_gram_cosine_similarity)
handlabeled$q_gram_2_cosine_similarity <- as.numeric(handlabeled$q_gram_2_cosine_similarity)

#p_load(rpart)
#p_load(party)
weights=rep(1, length(handlabeled$rex_match)) #Positive cases worth twice as much as negative cases
tree <- partykit::ctree(as.factor(rex_match) ~ q_gram_2_cosine_similarity,
              data=handlabeled,
              weights=weights,
              control=partykit::ctree_control(maxdepth=1)) #Find an optimal split 0.15
tree
#plot(tree)
table(predict(tree),handlabeled$rex_match)

weights=handlabeled$rex_match+1 #Positive cases worth twice as much as negative cases
tree <- partykit::ctree(as.factor(rex_match) ~ q_gram_2_cosine_similarity,
              data=handlabeled,
              weights=weights,
              control=ctree_control(maxdepth=1)) #Find an optimal split 0.15
tree
#plot(tree)
table(predict(tree),handlabeled$rex_match)

weights=(handlabeled$rex_match*9)+1 #Positive cases worth 10 times as much as negative cases
tree <- partykit::ctree(as.factor(rex_match) ~ q_gram_2_cosine_similarity,
              data=handlabeled,
              weights=weights,
              control=partykit::ctree_control(maxdepth=1)) #Find an optimal split 0.15
tree
#plot(tree)
table(predict(tree),handlabeled$rex_match)

results_list <- list()
for(i in 0:100){
  print(i)
  weights=(handlabeled$rex_match*i)+1 #Positive cases worth 10 times as much as negative cases
  tree <- partykit::ctree(as.factor(rex_match) ~ q_gram_2_cosine_similarity,
                data=handlabeled,
                weights=weights,
                control=ctree_control(maxdepth=1)) #Find an optimal split 0.15
  #tree
  #plot(tree)
  d <- table(predict(tree),handlabeled$rex_match)
  results_list[[as.character(i)]] <- data.frame(i=i,
                                                true_negative=d[1,1],
                                                false_negative=d[1,2],
                                                false_positive=d[2,1],
                                                true_positive=d[2,2], 
                                                #cosine_similarity=tree@tree$psplit$splitpoint) #name of part changed, is this correct?
                                                cosine_similarity=tree$node$split$breaks  
)

}

results_df <- rbindlist(results_list)
results_df$true_negative  <- ( results_df$true_negative / sum(handlabeled$rex_match==0)  ) %>% round(digits=3)
results_df$false_negative <- ( results_df$false_negative / sum(handlabeled$rex_match==1) ) %>% round(digits=3)
results_df$false_positive     <- ( results_df$false_positive / sum(handlabeled$rex_match==0)     ) %>% round(digits=3)
results_df$true_positive      <- ( results_df$true_positive / sum(handlabeled$rex_match==1)      ) %>% round(digits=3)

results_df$cosine_similarity <- results_df$cosine_similarity %>% round(digits=2)
results_df_unique <- subset(results_df, !duplicated(cosine_similarity))
results_df_unique <- subset(results_df_unique, !duplicated(false_negative))

ggplot(results_df_unique,
       aes(false_negative,false_positive,
           label=cosine_similarity)) + 
      geom_text() + 
      ggtitle("Cosine Similarity Threshold and False Pos./Neg. Rate")

table(handlabeled$q_gram_2_cosine_similarity>.05, handlabeled$rex_match)
table(handlabeled$q_gram_2_cosine_similarity>.1, handlabeled$rex_match)
table(handlabeled$q_gram_2_cosine_similarity>.2, handlabeled$rex_match)


```


```{r, eval=F, echo=F}

s_curve <- get_s_curve_new(
                       1000,
                       n_bands_min = 1,
                       n_rows_per_band_min = 1
                       )

s_curve <- get_s_curve_new(
                       256,
                       n_bands_min = 1,
                       n_rows_per_band_min = 1
                       )

```


(Moved chunk "03 Fuzzy Matcher Cut 1" to 12_cut_code)
(Moved chunk "03 Fuzzy Matcher Cut 2" to 12_cut_code)
(Moved chunk "03 Fuzzy Matcher Cut 3" to 12_cut_code)
(Moved chunk "03 Fuzzy Matcher Cut 4" to 12_cut_code)

   




